{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccd11db4-5a32-42a4-8272-9800d685a304",
   "metadata": {},
   "source": [
    "# RECOVER Codebase Tutorial\n",
    "This notebook serves as a tutorial for usage of the RECOVER codebase.  In this tutorial we will go over how to set up a new experiment and how to launch it.  We will detail the various configuration settings that can be manipulated, the different ways to use the datasets, models, and experimental setups.\n",
    "\n",
    "### Logical Structure of Codebase\n",
    "The RECOVER codebase makes heavy use of [Ray Tune](https://docs.ray.io/en/latest/tune/index.html).  The code implements a `tune.Trainable` object which is used for training.  By default a run using RECOVER will construct one of these `Trainable` classes (either a `BasicTrainer`, used for the simple supervised regression task, or the `ActiveTrainer` which implements active learning) and then Tune will run the experiment.  Given an object whose class is a subclass of `tune.Trainable` Tune will repeatedly call the `step` method on the object with the understanding that the `step` method will contain all logic to do optimization.  \n",
    "\n",
    "This, in effect, is how the RECOVER code works.  Each experiment run using the RECOVER pipeline requires a configuration object, defined in a python file in the `config` directory and assigned to the variable `configuration`.  We will go deeper into how to properly setup a configuration later, but for now note that some example config files can be found in the `config` directory at your leisure.  We will now move on to how an experiment is run, from start to finish, using the RECOVER pipeline.  First, a `Trainable` subclass will be instantiated.  During its initialization, we will build a dataset object based on configuration parameters.  The dataset object will hold the [DrugComb](https://drugcomb.fimm.fi/) dataset altered in specific ways to enable different random splits based on your configuration.  If you are running an active learning trial using the `ActiveTrainer` it will initialize a seen and unseen set, splitting the training set into two parts -- one which is the initial seen set which is visible to the learner and a second unseen set which the learner does not have access to but may query and add to its seen set to use for further learning.\n",
    "\n",
    "Next, Tune will take control of training and repeatedly call `step` on the `Trainable` object.  If using the `BasicTrainer` the `step` method will do optimization across the entire training set once and compute metrics on both the full training set and validation set.  If using the `ActiveTrainer` the `step` method will do optimization across the set of all drug combinations seen so far, doing early stopping on a held-out set of combinations.  Then, it will compute acquisition scores across the set of unseen drug combinations and choose the next batch of combinations to query and unmask.  Finally, the `ActiveTrainer.step` method will compute metrics across the seen set and also compute multiple metrics to track the quality of the active learning queries themselves.  Note that Tune will automatically log all the metrics returned by the `step` method to Tensorboard.\n",
    "\n",
    "Since running with Tune requires Ray and can take slightly longer to setup, we also provide the option to run without Tune by setting `use_tune = False` in the configuration.  This will let things run slightly faster, but bars you from doing easy hyperparameter search as in Tune or benefiting from Tune's automatic logging.\n",
    "\n",
    "Next we'll look at an example run of the RECOVER code, before finally going over what each configuration controls in more detail.\n",
    "\n",
    "## An Example Run of RECOVER\n",
    "Since Ray is a distributed processing library and since this tutorial is using an `ipynb` we're going to run without Ray Tune.  However, we generally recommend using Ray Tune as it provides many benefits when running on a cluster or otherwise.\n",
    "\n",
    "Let's begin begin by importing some things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "969ffef7-c110-4402-84d6-9a2b78e06e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recover.train import train\n",
    "from recover.datasets.drugcomb_matrix_data import DrugCombMatrix\n",
    "from recover.models.models import Baseline\n",
    "from recover.models.predictors import BilinearFilmMLPPredictor, BilinearMLPPredictor\n",
    "from recover.utils.utils import get_project_root\n",
    "from recover.train import train_epoch, eval_epoch, BasicTrainer\n",
    "import os\n",
    "from ray import tune\n",
    "from importlib import import_module\n",
    "\n",
    "########################################################################################################################\n",
    "# Configuration\n",
    "########################################################################################################################\n",
    "\n",
    "\n",
    "pipeline_config = {\n",
    "    \"use_tune\": False,\n",
    "    \"num_epoch_without_tune\": 50,  \n",
    "    \"seed\": 0,\n",
    "    # Optimizer config\n",
    "    \"lr\": 1e-4,\n",
    "    \"weight_decay\": 1e-2,\n",
    "    \"batch_size\": 128,\n",
    "    # Train epoch and eval_epoch to use\n",
    "    \"train_epoch\": train_epoch,\n",
    "    \"eval_epoch\": eval_epoch,\n",
    "}\n",
    "\n",
    "predictor_config = {\n",
    "    \"predictor\": BilinearMLPPredictor,\n",
    "    \"predictor_layers\":\n",
    "        [\n",
    "            2048,\n",
    "            128,\n",
    "            64,\n",
    "            1,\n",
    "        ],\n",
    "    \"merge_n_layers_before_the_end\": 2,  # Computation on the sum of the two drug embeddings for the last n layers\n",
    "    \"allow_neg_eigval\": True,\n",
    "}\n",
    "\n",
    "model_config = {\n",
    "    \"model\": Baseline,\n",
    "    \"load_model_weights\": False,\n",
    "}\n",
    "\n",
    "dataset_config = {\n",
    "    \"dataset\": DrugCombMatrix,\n",
    "    \"study_name\": 'ALMANAC',\n",
    "    \"in_house_data\": 'without',\n",
    "    \"val_set_prop\": 0.2,\n",
    "    \"test_set_prop\": 0.1,\n",
    "    \"split_valid_train\": \"pair_level\",\n",
    "    \"cell_line\": 'MCF7',  \n",
    "    \"target\": \"bliss_max\",\n",
    "    \"fp_bits\": 1024,\n",
    "    \"fp_radius\": 2\n",
    "}\n",
    "\n",
    "########################################################################################################################\n",
    "# Configuration that will be loaded\n",
    "########################################################################################################################\n",
    "\n",
    "configuration = {\n",
    "    \"trainer\": BasicTrainer, \n",
    "    \"trainer_config\": {\n",
    "        **pipeline_config,\n",
    "        **predictor_config,\n",
    "        **model_config,\n",
    "        **dataset_config,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61260c23-a976-4ed0-a9f8-c8883542dbc7",
   "metadata": {},
   "source": [
    "This configuration tells us to run 50 epochs of training on the ALMANAC dataset restricted to the MCF7 cell line.  We're going to split the dataset by drug pair so that no drug pair may be present in more than one of the training, validation, or test set.  The parameters `fp_bits` and `fp_radius` control parameters of the morgan fingerprint of the drugs in a combination -- we use this as part of the features for each drug pair.\n",
    "We'll be running without using active learning (hence our usage of the `BasicTrainer`) and we'll be using a 4 layer multi-layer perceptron (MLP) as our predictor.  To allow for symmetry in our predictor's drug combination predictions (i.e., for drugs $A, B$ we require that $f(A,B) = f(B,A)$ for predictor $f$) we merge the drug representations into a combined representation, and the layer of the MLP at which this is done is denoted by the parameter `merge_n_layers_before_end`.  We are using a `BilinearMLPPredictor` which computes predictions via $h_1 W^T W h_2$ where $h_1, h_2$ are the representation of drugs $A$ and $B$ respectively.  Next we'll call `train` to begin training.  Note that we're just calling `train` here for demonstration purposes.  When usually running it is better to call `python train.py` from the command line with the config passed as an argument, as well as running with Tune enabled.  We're only disabling Tune here as we're working in a Jupyter notebook, where Ray Tune doesn't really make as much sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db00455c-35ea-4740-a8ca-55c43313b43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing regular training pipeline\n",
      "Dataset loaded.\n",
      "4463 drug comb experiments among 149 drugs\n",
      "\t fingeprints with radius 2 and nbits 1024\n",
      "\t drug features dimension 1173\n",
      "\t 1 cell-lines\n",
      "model initialized randomly\n",
      "Baseline(\n",
      "  (criterion): MSELoss()\n",
      "  (predictor): BilinearMLPPredictor(\n",
      "    (before_merge_mlp): Sequential(\n",
      "      (0): LinearModule(in_features=1173, out_features=2048, bias=True)\n",
      "      (1): ReLUModule()\n",
      "      (2): LinearModule(in_features=2048, out_features=128, bias=True)\n",
      "      (3): ReLUModule()\n",
      "    )\n",
      "    (after_merge_mlp): Sequential(\n",
      "      (0): LinearModule(in_features=128, out_features=64, bias=True)\n",
      "      (1): ReLUModule()\n",
      "      (2): LinearModule(in_features=64, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Training {'loss_mean': 137.83404617309571, 'comb_r_squared': 0.008456869497901563}\n",
      "Testing {'loss_mean': 96.26114654541016, 'comb_r_squared': 0.08663332884535772, 'spearman': 0.2269973471653043} \n",
      "\n",
      "Training {'loss_mean': 73.85206871032715, 'comb_r_squared': 0.1095997661657876}\n",
      "Testing {'loss_mean': 59.805132729666575, 'comb_r_squared': 0.24730857136368478, 'spearman': 0.36180800901103355} \n",
      "\n",
      "Training {'loss_mean': 61.96979248046875, 'comb_r_squared': 0.22050704937078097}\n",
      "Testing {'loss_mean': 51.68771089826311, 'comb_r_squared': 0.3393093486713353, 'spearman': 0.4274404323586847} \n",
      "\n",
      "Training {'loss_mean': 57.90300132751465, 'comb_r_squared': 0.2716191762880728}\n",
      "Testing {'loss_mean': 48.29570416041783, 'comb_r_squared': 0.38239521106910146, 'spearman': 0.46174320319097323} \n",
      "\n",
      "Training {'loss_mean': 55.50776977539063, 'comb_r_squared': 0.3017356112077475}\n",
      "Testing {'loss_mean': 46.84081758771624, 'comb_r_squared': 0.40135413937101144, 'spearman': 0.47612427061030704} \n",
      "\n",
      "Training {'loss_mean': 54.408232040405274, 'comb_r_squared': 0.3161468445764271}\n",
      "Testing {'loss_mean': 46.331942967006135, 'comb_r_squared': 0.407989096335822, 'spearman': 0.47982519571244486} \n",
      "\n",
      "Training {'loss_mean': 53.98149215698242, 'comb_r_squared': 0.3220900453327072}\n",
      "Testing {'loss_mean': 46.24688529968262, 'comb_r_squared': 0.4093937955132582, 'spearman': 0.4810103095611103} \n",
      "\n",
      "Training {'loss_mean': 53.75645408630371, 'comb_r_squared': 0.3254675161032479}\n",
      "Testing {'loss_mean': 46.262716838291716, 'comb_r_squared': 0.40954295277074637, 'spearman': 0.4816342312860164} \n",
      "\n",
      "Training {'loss_mean': 53.62065368652344, 'comb_r_squared': 0.32751859371018116}\n",
      "Testing {'loss_mean': 46.28363473074777, 'comb_r_squared': 0.40968671363835896, 'spearman': 0.48184352562304034} \n",
      "\n",
      "Training {'loss_mean': 53.55688064575195, 'comb_r_squared': 0.3286819462509869}\n",
      "Testing {'loss_mean': 46.28681073869978, 'comb_r_squared': 0.4102454541851764, 'spearman': 0.48235666551781564} \n",
      "\n",
      "Training {'loss_mean': 53.49986846923828, 'comb_r_squared': 0.3297840498705204}\n",
      "Testing {'loss_mean': 46.32572364807129, 'comb_r_squared': 0.41038459100196184, 'spearman': 0.4823462250179646} \n",
      "\n",
      "Training {'loss_mean': 53.44655174255371, 'comb_r_squared': 0.3306163046594637}\n",
      "Testing {'loss_mean': 46.26529448372977, 'comb_r_squared': 0.4116334209229999, 'spearman': 0.48269647407527055} \n",
      "\n",
      "Training {'loss_mean': 53.38120285034179, 'comb_r_squared': 0.33169016693347725}\n",
      "Testing {'loss_mean': 46.2331850869315, 'comb_r_squared': 0.4127521934967019, 'spearman': 0.4826814827168334} \n",
      "\n",
      "Training {'loss_mean': 53.324722900390626, 'comb_r_squared': 0.33243050769824284}\n",
      "Testing {'loss_mean': 46.11578369140625, 'comb_r_squared': 0.4149492485578123, 'spearman': 0.4835008516986771} \n",
      "\n",
      "Training {'loss_mean': 53.25282859802246, 'comb_r_squared': 0.3335935954836436}\n",
      "Testing {'loss_mean': 46.01110185895647, 'comb_r_squared': 0.41710289783516447, 'spearman': 0.4832793321920234} \n",
      "\n",
      "Training {'loss_mean': 53.14934646606445, 'comb_r_squared': 0.33498487833123003}\n",
      "Testing {'loss_mean': 45.867144448416575, 'comb_r_squared': 0.4193744749063031, 'spearman': 0.48391655065020867} \n",
      "\n",
      "Training {'loss_mean': 52.923891677856446, 'comb_r_squared': 0.33792162319039243}\n",
      "Testing {'loss_mean': 45.54397010803223, 'comb_r_squared': 0.4233073026106433, 'spearman': 0.4844654587401536} \n",
      "\n",
      "Training {'loss_mean': 52.62699630737305, 'comb_r_squared': 0.3412773146031115}\n",
      "Testing {'loss_mean': 45.21293694632394, 'comb_r_squared': 0.4270012834348042, 'spearman': 0.48564041664541713} \n",
      "\n",
      "Training {'loss_mean': 52.11554794311523, 'comb_r_squared': 0.3471892295310891}\n",
      "Testing {'loss_mean': 44.48108100891113, 'comb_r_squared': 0.4336997452665908, 'spearman': 0.48769712164673146} \n",
      "\n",
      "Training {'loss_mean': 51.36767509460449, 'comb_r_squared': 0.35589319471959086}\n",
      "Testing {'loss_mean': 43.895595005580354, 'comb_r_squared': 0.4420963141200392, 'spearman': 0.490549504528867} \n",
      "\n",
      "Training {'loss_mean': 50.77073654174805, 'comb_r_squared': 0.3635772979892936}\n",
      "Testing {'loss_mean': 43.05243437630789, 'comb_r_squared': 0.4519745533020334, 'spearman': 0.4935319309606965} \n",
      "\n",
      "Training {'loss_mean': 49.8977774810791, 'comb_r_squared': 0.3743116542369558}\n",
      "Testing {'loss_mean': 42.248943601335796, 'comb_r_squared': 0.4617747397862458, 'spearman': 0.4945089935212576} \n",
      "\n",
      "Training {'loss_mean': 49.103035888671876, 'comb_r_squared': 0.3840689024985798}\n",
      "Testing {'loss_mean': 41.48883220127651, 'comb_r_squared': 0.47170830024406496, 'spearman': 0.49544189367220104} \n",
      "\n",
      "Training {'loss_mean': 48.45191246032715, 'comb_r_squared': 0.3925732585848639}\n",
      "Testing {'loss_mean': 40.982198987688335, 'comb_r_squared': 0.47857989524152983, 'spearman': 0.49532665315492674} \n",
      "\n",
      "Training {'loss_mean': 47.84350952148438, 'comb_r_squared': 0.40027244154761477}\n",
      "Testing {'loss_mean': 40.59366989135742, 'comb_r_squared': 0.48379118604114635, 'spearman': 0.4946586672367817} \n",
      "\n",
      "Training {'loss_mean': 47.16923614501953, 'comb_r_squared': 0.4084059881986926}\n",
      "Testing {'loss_mean': 40.28249876839774, 'comb_r_squared': 0.4882991789185765, 'spearman': 0.4955458168044891} \n",
      "\n",
      "Training {'loss_mean': 46.694303588867186, 'comb_r_squared': 0.41424659609724696}\n",
      "Testing {'loss_mean': 40.07681901114328, 'comb_r_squared': 0.49159518149485654, 'spearman': 0.4952047884092221} \n",
      "\n",
      "Training {'loss_mean': 46.143807830810545, 'comb_r_squared': 0.4209480717989016}\n",
      "Testing {'loss_mean': 39.875353404453826, 'comb_r_squared': 0.4938399853086641, 'spearman': 0.49625776435475905} \n",
      "\n",
      "Training {'loss_mean': 45.74955940246582, 'comb_r_squared': 0.4259191292345226}\n",
      "Testing {'loss_mean': 39.79540824890137, 'comb_r_squared': 0.4957817952724541, 'spearman': 0.4977354005346754} \n",
      "\n",
      "Training {'loss_mean': 45.29211486816406, 'comb_r_squared': 0.43149689936525987}\n",
      "Testing {'loss_mean': 39.70611081804548, 'comb_r_squared': 0.4971381480412495, 'spearman': 0.4984585294147744} \n",
      "\n",
      "Training {'loss_mean': 44.849169921875, 'comb_r_squared': 0.43703493481250594}\n",
      "Testing {'loss_mean': 39.67780794416155, 'comb_r_squared': 0.4982330587787723, 'spearman': 0.5004298827048302} \n",
      "\n",
      "Training {'loss_mean': 44.39664520263672, 'comb_r_squared': 0.4427333237604332}\n",
      "Testing {'loss_mean': 39.676866803850444, 'comb_r_squared': 0.49757626439561925, 'spearman': 0.5020702297944425} \n",
      "\n",
      "Training {'loss_mean': 43.995890579223634, 'comb_r_squared': 0.4475937897716002}\n",
      "Testing {'loss_mean': 39.74396923610142, 'comb_r_squared': 0.49760804808474984, 'spearman': 0.5052440192781832} \n",
      "\n",
      "Training {'loss_mean': 43.63889717102051, 'comb_r_squared': 0.45228333367140955}\n",
      "Testing {'loss_mean': 39.789961678641184, 'comb_r_squared': 0.4970371430899125, 'spearman': 0.5060843993223154} \n",
      "\n",
      "Training {'loss_mean': 43.23696182250976, 'comb_r_squared': 0.4570479316208342}\n",
      "Testing {'loss_mean': 39.85498700823103, 'comb_r_squared': 0.4972314416392709, 'spearman': 0.5082059410313692} \n",
      "\n",
      "Training {'loss_mean': 42.82843063354492, 'comb_r_squared': 0.46212393005192404}\n",
      "Testing {'loss_mean': 40.33893585205078, 'comb_r_squared': 0.4910267755669972, 'spearman': 0.5089771094412638} \n",
      "\n",
      "Training {'loss_mean': 42.37292930603027, 'comb_r_squared': 0.4676812419310184}\n",
      "Testing {'loss_mean': 40.43770054408482, 'comb_r_squared': 0.49036014939031713, 'spearman': 0.5097146523111294} \n",
      "\n",
      "Training {'loss_mean': 42.06132171630859, 'comb_r_squared': 0.47149144745363725}\n",
      "Testing {'loss_mean': 40.88156809125628, 'comb_r_squared': 0.48552331194031967, 'spearman': 0.5091082640612726} \n",
      "\n",
      "Training {'loss_mean': 41.76662826538086, 'comb_r_squared': 0.4751389057537149}\n",
      "Testing {'loss_mean': 41.125840868268696, 'comb_r_squared': 0.4829072414365514, 'spearman': 0.5084575899661776} \n",
      "\n",
      "Training {'loss_mean': 41.571766738891604, 'comb_r_squared': 0.47757959391082133}\n",
      "Testing {'loss_mean': 41.31006758553641, 'comb_r_squared': 0.4816242537851355, 'spearman': 0.5064756536969647} \n",
      "\n",
      "Training {'loss_mean': 41.30339309692383, 'comb_r_squared': 0.48108073717046396}\n",
      "Testing {'loss_mean': 41.776963642665315, 'comb_r_squared': 0.47605996696509584, 'spearman': 0.5038982365579965} \n",
      "\n",
      "Training {'loss_mean': 41.1009398651123, 'comb_r_squared': 0.4836468907849299}\n",
      "Testing {'loss_mean': 41.87168966020857, 'comb_r_squared': 0.4748949595447143, 'spearman': 0.5044912151283328} \n",
      "\n",
      "Training {'loss_mean': 40.92785194396973, 'comb_r_squared': 0.48585951852973774}\n",
      "Testing {'loss_mean': 42.080077852521626, 'comb_r_squared': 0.47308579141131485, 'spearman': 0.5026730087617635} \n",
      "\n",
      "Training {'loss_mean': 40.62038856506348, 'comb_r_squared': 0.48975186016969097}\n",
      "Testing {'loss_mean': 42.062967027936665, 'comb_r_squared': 0.4734159316689219, 'spearman': 0.5001701491017493} \n",
      "\n",
      "Training {'loss_mean': 40.36729141235352, 'comb_r_squared': 0.4927447032695012}\n",
      "Testing {'loss_mean': 42.53833934238979, 'comb_r_squared': 0.4679119205913879, 'spearman': 0.49935285562920556} \n",
      "\n",
      "Training {'loss_mean': 40.012057342529296, 'comb_r_squared': 0.49719638744934946}\n",
      "Testing {'loss_mean': 42.512952259608674, 'comb_r_squared': 0.46847959770309416, 'spearman': 0.498322897241923} \n",
      "\n",
      "Training {'loss_mean': 39.786815032958984, 'comb_r_squared': 0.4999191650525244}\n",
      "Testing {'loss_mean': 42.68407222202846, 'comb_r_squared': 0.4666901983266956, 'spearman': 0.4958671941825127} \n",
      "\n",
      "Training {'loss_mean': 39.47365036010742, 'comb_r_squared': 0.5037038927094917}\n",
      "Testing {'loss_mean': 42.584524154663086, 'comb_r_squared': 0.46839008756660383, 'spearman': 0.4943603053080724} \n",
      "\n",
      "Training {'loss_mean': 39.08170433044434, 'comb_r_squared': 0.5085307349732421}\n",
      "Testing {'loss_mean': 42.710205350603374, 'comb_r_squared': 0.46729006201625123, 'spearman': 0.49357334834615485} \n",
      "\n",
      "Training {'loss_mean': 38.70839286804199, 'comb_r_squared': 0.5130656843021131}\n",
      "Testing {'loss_mean': 42.91427421569824, 'comb_r_squared': 0.4652382599758155, 'spearman': 0.4947985823979108} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4d833f-6214-4292-a1ab-a835d1eac7e7",
   "metadata": {},
   "source": [
    "We can see that by the end we arrive to an $R^2$ value of ~$0.497$ for the test set and a spearman rank correlation of $0.509$.  If we run without tune as we do here results will only be printed on the command line like so, but if we run with tune then one can access the results via tensorboard or even using Wandb by following the instructions [here](https://docs.wandb.ai/guides/integrations/other/ray-tune).  To do the same run as above but with tune we simply need to take the `configuration` we wrote and put it in some file and make a few changes to it.  A configuration like the above but usable with tune can be found in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a135a14-130e-43ed-b367-b0f8f3f5ee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recover.datasets.drugcomb_matrix_data import DrugCombMatrix\n",
    "from recover.models.models import Baseline\n",
    "from recover.models.predictors import BilinearFilmMLPPredictor, BilinearMLPPredictor\n",
    "from recover.utils.utils import get_project_root\n",
    "from recover.train import train_epoch, eval_epoch, BasicTrainer\n",
    "import os\n",
    "from ray import tune\n",
    "from importlib import import_module\n",
    "\n",
    "pipeline_config = {\n",
    "    \"use_tune\": True,\n",
    "    \"seed\": 0,\n",
    "    # Optimizer config\n",
    "    \"lr\": 1e-4,\n",
    "    \"weight_decay\": 1e-2,\n",
    "    \"batch_size\": 128,\n",
    "    # Train epoch and eval_epoch to use\n",
    "    \"train_epoch\": train_epoch,\n",
    "    \"eval_epoch\": eval_epoch,\n",
    "}\n",
    "\n",
    "predictor_config = {\n",
    "    \"predictor\": BilinearMLPPredictor,\n",
    "    \"predictor_layers\":\n",
    "        [\n",
    "            2048,\n",
    "            128,\n",
    "            64,\n",
    "            1,\n",
    "        ],\n",
    "    \"merge_n_layers_before_the_end\": 2,  # Computation on the sum of the two drug embeddings for the last n layers\n",
    "    \"allow_neg_eigval\": True,\n",
    "}\n",
    "\n",
    "model_config = {\n",
    "    \"model\": Baseline,\n",
    "    \"load_model_weights\": False,\n",
    "}\n",
    "\n",
    "dataset_config = {\n",
    "    \"dataset\": DrugCombMatrix,\n",
    "    \"study_name\": 'ALMANAC',\n",
    "    \"in_house_data\": 'without',\n",
    "    \"val_set_prop\": 0.2,\n",
    "    \"test_set_prop\": 0.1,\n",
    "    \"split_valid_train\": \"pair_level\",\n",
    "    \"cell_line\": 'MCF7', \n",
    "    \"target\": \"bliss_max\",\n",
    "    \"fp_bits\": 1024,\n",
    "    \"fp_radius\": 2\n",
    "}\n",
    "\n",
    "########################################################################################################################\n",
    "# Configuration that will be loaded\n",
    "########################################################################################################################\n",
    "\n",
    "configuration = {\n",
    "    \"trainer\": BasicTrainer,\n",
    "    \"trainer_config\": {\n",
    "        **pipeline_config,\n",
    "        **predictor_config,\n",
    "        **model_config,\n",
    "        **dataset_config,\n",
    "    },\n",
    "    \"summaries_dir\": os.path.join(get_project_root(), \"RayLogs\"),\n",
    "    \"memory\": 1800,\n",
    "    \"stop\": {\"training_iteration\": 1000, 'patience': 10},\n",
    "    \"checkpoint_score_attr\": 'eval/comb_r_squared',\n",
    "    \"keep_checkpoints_num\": 1, # This means we'll only checkpoint the model with the best R^2 on the validation set\n",
    "    \"checkpoint_at_end\": False,\n",
    "    \"checkpoint_freq\": 1,\n",
    "    \"resources_per_trial\": {\"cpu\": 8, \"gpu\": 0},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359a128a-1214-4ac7-8169-cc3e8bf41a3a",
   "metadata": {},
   "source": [
    "To run with tune, one could just copy the above into a file titled, say, `my_config.py` and then launch the experiment by running `python train.py -c my_config` from the command line.  The `train.py` script will invoke ray properly and do all setup of the experiment and, finally, launch the experiment.  The name and log directory for the experiment will be printed by ray and so to view the experiment results via tensorboard one can simply run \n",
    "\n",
    "```\n",
    "$ cd <log_dir_printed_by_ray>\n",
    "$ tensorboard --logdir=. --host localhost --port 8080\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099e5251-ac29-4c65-945e-6f8809b76754",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gfn_exploration",
   "language": "python",
   "name": "gfn_exploration"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
